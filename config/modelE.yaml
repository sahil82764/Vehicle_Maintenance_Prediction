cross_validation: 5 

models:
  - model_name: sklearn.linear_model.LogisticRegression
    hyperparameters:
      C: [0.1, 1, 10]
      solver: ['liblinear', 'saga']

  - model_name: sklearn.ensemble.RandomForestClassifier
    hyperparameters:
      n_estimators: [50, 100, 150]
      max_depth: [5, 10, 20]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]

  - model_name: sklearn.linear_model.SGDClassifier
    hyperparameters:
      loss: ['log_loss', 'modified_huber'] # For binary classification
      penalty: ['l2', 'l1', 'elasticnet']
      alpha: [0.0001, 0.001, 0.01]

  - model_name: sklearn.tree.DecisionTreeClassifier
    hyperparameters:
      max_depth: [5, 10, 20] 
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      criterion: ['gini', 'entropy', 'log_loss']

  - model_name: xgboost.XGBClassifier
    hyperparameters:
      n_estimators: [50, 100, 150]
      learning_rate: [0.01, 0.1, 0.5]
      max_depth: [3, 5, 7]
      subsample: [0.8, 1.0]
      objective: ['binary:logistic']

  - model_name: sklearn.linear_model.LinearRegression
    hyperparameters:
      fit_intercept: [True] #Reduced to only one value.
      positive: [False] #Reduced to only one value.

  - model_name: sklearn.linear_model.Ridge
    hyperparameters:
      alpha: [1.0, 10.0] #Reduced the range and number of values
      solver: ['auto', 'svd'] #Reduced the number of solvers
      max_iter: [1000] #Reduced to one value.

  - model_name: sklearn.ensemble.RandomForestRegressor
    hyperparameters:
      n_estimators: [50, 100] #Reduced the number of estimators
      max_depth: [10, 20] #Reduced the range
      min_samples_split: [2, 10] #Reduced the number of values
      min_samples_leaf: [1, 4] #Reduced the number of values

  - model_name: sklearn.ensemble.GradientBoostingRegressor
    hyperparameters:
      n_estimators: [50, 100] #Reduced the number of estimators
      learning_rate: [0.1, 0.5] #Reduced the range
      max_depth: [3, 7] #Reduced the range
      subsample: [1.0] #Reduced to only one value.

  - model_name: xgboost.XGBRegressor
    hyperparameters:
      n_estimators: [50, 100] #Reduced the number of estimators.
      learning_rate: [0.1, 0.5] #Reduced the range
      max_depth: [3, 7] #Reduced the range
      subsample: [1.0] #Reduced to only one value