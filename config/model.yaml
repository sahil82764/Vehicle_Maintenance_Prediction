cross_validation: 5 

models:
  - model_name: sklearn.linear_model.LogisticRegression
    hyperparameters:
      C: [0.1, 1, 10]
      solver: ['liblinear', 'saga']

  - model_name: sklearn.ensemble.RandomForestClassifier
    hyperparameters:
      n_estimators: [50, 100, 150]
      max_depth: [5, 10, 20]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]

  - model_name: sklearn.linear_model.SGDClassifier
    hyperparameters:
      loss: ['log_loss', 'modified_huber'] # For binary classification
      penalty: ['l2', 'l1', 'elasticnet']
      alpha: [0.0001, 0.001, 0.01]

  - model_name: sklearn.tree.DecisionTreeClassifier
    hyperparameters:
      max_depth: [5, 10, 20] 
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      criterion: ['gini', 'entropy', 'log_loss']

  - model_name: xgboost.XGBClassifier
    hyperparameters:
      n_estimators: [50, 100, 150]
      learning_rate: [0.01, 0.1, 0.5]
      max_depth: [3, 5, 7]
      subsample: [0.8, 1.0]
      objective: ['binary:logistic']